import pandas as pd
from datetime import datetime
import traceback
import re

# === Constants ===
UNNECESSARY_COLUMNS = [
    "Descri√ß√£o monitoramento", "Link servi√ßo", "Descri√ß√£o Pai", "Link ocorr√™ncia Pai", "Thumbnail",
    "Thumbnail pai", "Data coleta", "Linguagem", "Foto publicador", "PageRank", "Estrelas",
    "Qualifica√ß√£o", "Qualificada por", "Data da qualifica√ß√£o", "Qualifica√ß√£o autom√°tica", "Para",
    "Latitude", "Longitude", "Id ocorr√™ncia no servi√ßo", "Id ocorr√™ncia pai no servi√ßo",
    "Link id ocorr√™ncia pai", "Arquivada", "Desarquivada", "Data Resposta",
    "Manifesta√ß√µes Detalhadas", "Termos", "Links", "Perfis", "Hashtags",
    "comments", "shares", "likes", "dislikes", "love", "wow", "haha", "sad", "angry",
    "thankful", "pride", "retweets", "favorites", "rating", "vendas", "resenhas", "votes", "views", "quotes",
    "videoViews", "URL da busca", "Id publicador", "Qualifica√ß√£o aprovada por", "Analisada por",
    "Data analisada", "Avalia√ß√£o", "Tipo/Conte√∫do", "Observa√ß√£o", "Unnamed: 73"
]

ENGAGEMENT_COLS = [
    "comments", "shares", "likes", "dislikes", "love", "wow", "haha", "sad", "angry",
    "thankful", "pride", "retweets", "favorites", "rating", "vendas",
    "resenhas", "votes", "views", "quotes"
]

LIST_CASA = ["C√ÇMARA", "SENADO"]
LIST_PARTIDO = ["MDB", "PT", "PRD", "PP", "PSDB", "PDT", "UNI√ÉO", "PL", "PODEMOS", "PSB", "REPUBLICANOS",
                 "PV", "AVANTE", "PSC", "PSOL", "PCDOB", "PSD", "SOLIDARIEDADE", "NOVO", "REDE", "PMB",
                 "UP", "DC", "PCO", "PSTU", "PCB", "PRTB", "MOBILIZA", "AGIR", "CIDADANIA", "PROS", "PATRIOTA"]
LIST_ESTADO = ["AC", "AL", "AP", "AM", "BA", "CE", "DF", "ES", "GO", "MA", "MT", "MS", "MG", "PA", "PB",
                "PR", "PE", "PI", "RJ", "RN", "RS", "RO", "RR", "SC", "SP", "SE", "TO"]

SPECIFIC_OVERRIDES = {
    "Nilto Tatto": {"Partido": "PT", "Estado": "SP"},
    "Socorro Neri": {"Partido": "PP", "Estado": "AC"},
    "AJ Albuquerque": {"Partido": "PP", "Estado": "CE"},
    "Duarte Junior": {"Partido": "PSB", "Estado": "MA"},
    "Julio Cesar": {"Partido": "PSD", "Estado": "PI"},
    "J√∫lio C√©sar": {"Partido": "PSD", "Estado": "PI"},
    "Vicentinho J√∫nior": {"Partido": "PP", "Estado": "TO"},
    "Yury do Pared√£o": {"Partido": "MDB", "Estado": "CE"}
}

# === Utility Function for IRAMUTEQ ===
def export_for_iramuteq(df, txt_filename):
    def clean_description(text):
        return re.sub(r'[\|:\*"\?<>\|\$\-\'%]', '', str(text))

    lines = []
    for _, row in df.iterrows():
        id_val = row.get("ID", "")
        nome = row.get("Nome publicador", "")
        descricao = clean_description(row.get("Descri√ß√£o", ""))
        lines.append(f"**** *id_{id_val} *u_{nome}\n{descricao}\n")

    with open(txt_filename, "w", encoding="utf-8") as f:
        f.writelines(lines)

    print(f"üßæ Arquivo IRAMUTEQ salvo como: {txt_filename}")

# === Core functions ===
def load_and_clean_sheet(filepath, sheet_name, is_main=True):
    df = pd.read_excel(filepath, sheet_name=sheet_name, skiprows=4)
    df.columns = df.columns.str.replace('"', '').str.strip()
    if is_main:
        df.insert(0, 'ID', range(1, len(df) + 1))
    return df

def clean_columns_and_values(df):
    # Sum "Manifesta√ß√µes reais" before dropping engagement columns
    engagement_present = [col for col in ENGAGEMENT_COLS if col in df.columns]
    if engagement_present:
        df["Manifesta√ß√µes reais"] = df[engagement_present].apply(pd.to_numeric, errors='coerce').sum(axis=1)
        if "Manifesta√ß√µes" in df.columns:
            idx = df.columns.get_loc("Manifesta√ß√µes") + 1
            cols = df.columns.tolist()
            cols.insert(idx, cols.pop(cols.index("Manifesta√ß√µes reais")))
            df = df[cols]

    df = df.drop(columns=set(UNNECESSARY_COLUMNS).intersection(df.columns), errors="ignore")
    df = df.replace("-", "NA").dropna(axis=1, how="all")

    for col in ['Perfil/Nome da busca', 'Servi√ßo']:
        if col in df.columns:
            df[col] = df[col].str.split(r"[-,]").str[0].str.strip()

    return df

def process_grupos_column(df):
    if "Grupos" in df.columns:
        df['Grupos'] = df['Grupos'].str.upper()

        def split_grupos(row):
            items = row.split(" | ") if isinstance(row, str) else []
            casa = partido = estado = extras = None
            items = ["C√ÇMARA" if i == "CAMARA" else i for i in items]
            items = ["PODEMOS" if i == "PODE" else i for i in items]
            for item in items:
                if item in LIST_CASA and not casa:
                    casa = item
                elif item in LIST_PARTIDO and not partido:
                    partido = item
                elif item in LIST_ESTADO and not estado:
                    estado = item
                else:
                    extras = extras + " | " + item if extras else item
            return casa, partido, estado, extras

        df[['Casa', 'Partido', 'Estado', 'Extras']] = df['Grupos'].apply(split_grupos).apply(pd.Series)
        df = df.drop(columns=['Grupos'])

    if 'Perfil/Nome da busca' in df.columns:
        for name, overrides in SPECIFIC_OVERRIDES.items():
            mask = df['Perfil/Nome da busca'].str.contains(name, na=False, case=False)
            for key, value in overrides.items():
                df.loc[mask, key] = value

    # Drop columns if all values are null
    for col in ['Casa', 'Partido', 'Estado']:
        if col in df.columns and df[col].isnull().all():
            df = df.drop(columns=[col])

    return df

def enrich_parlamentar_and_date(df):
    def get_title(casa):
        return "Deputado(a)" if casa == "C√ÇMARA" else "Senador(a)" if casa == "SENADO" else ""

    if {'Casa', 'Perfil/Nome da busca', 'Partido', 'Estado'}.issubset(df.columns):
        df['Parlamentar'] = df.apply(
            lambda row: f"{get_title(row['Casa'])} {row['Perfil/Nome da busca']} ({row['Partido']}/{row['Estado']})",
            axis=1
        )

    if "Data publica√ß√£o" in df.columns:
        df["Data publica√ß√£o - Date"] = df["Data publica√ß√£o"].str[:8].str.strip()
        df["Data publica√ß√£o - Hour"] = df["Data publica√ß√£o"].str[9:].str.strip()
        df = df.drop(columns=["Data publica√ß√£o"])

    if "Data publica√ß√£o - Date" in df.columns:
        df["Data publica√ß√£o - Date"] = pd.to_datetime(df["Data publica√ß√£o - Date"], format="%d/%m/%y", errors='coerce')
        df["Data publica√ß√£o - Date"] = df["Data publica√ß√£o - Date"].dt.strftime("%d/%m/%Y")
        df["Dia"] = pd.to_datetime(df["Data publica√ß√£o - Date"], format="%d/%m/%Y", errors='coerce').dt.day
        df["M√™s"] = pd.to_datetime(df["Data publica√ß√£o - Date"], format="%d/%m/%Y", errors='coerce').dt.month
        df["Ano"] = pd.to_datetime(df["Data publica√ß√£o - Date"], format="%d/%m/%Y", errors='coerce').dt.year

    if "Data publica√ß√£o - Hour" in df.columns:
        df["Hora"] = df["Data publica√ß√£o - Hour"].str[:2]

    return df

def add_analysis_column_and_export_txt(df, txt_filename):
    for col in ['ID', 'Descri√ß√£o', 'Manifesta√ß√µes', 'Link ocorr√™ncia']:
        if col not in df.columns:
            df[col] = ""

    df["An√°lise"] = (
        "ID: " + df["ID"].astype(str) +
        " | Texto: " + df["Descri√ß√£o"].astype(str) +
        " | Engajamento: " + df["Manifesta√ß√µes"].astype(str) +
        " | Link: " + df["Link ocorr√™ncia"].astype(str)
    )

    df["An√°lise"].to_csv(txt_filename, index=False, header=False)
    print(f"üìù Arquivo .txt salvo como: {txt_filename}")
    return df

def process_and_export_excel(filepath, output_filename):
    print(f"üìÇ Processando arquivo: {filepath}")

    df_main = load_and_clean_sheet(filepath, sheet_name="Ocorr√™ncias", is_main=True)
    df_main = df_main.reset_index(drop=True)
    df_combined = df_main.copy()

    try:
        df_tags = load_and_clean_sheet(filepath, sheet_name="Tags", is_main=False)
        df_tags = df_tags.reset_index(drop=True)
        tag_fallback = pd.DataFrame(0, index=range(len(df_main)), columns=df_tags.columns)
        df_tags = df_tags.applymap(lambda x: 1 if str(x).strip().upper() == "SIM" else 0)
        rows_to_fill = min(len(df_tags), len(tag_fallback))
        tag_fallback.iloc[:rows_to_fill] = df_tags.iloc[:rows_to_fill]
        df_combined = pd.concat([df_main, tag_fallback], axis=1)
        print("‚úÖ Tags processadas linha a linha com fallback zero.")
    except Exception as e:
        print("‚ö†Ô∏è Aba 'Tags' n√£o encontrada ou erro ao carregar:", str(e))
        traceback.print_exc()

    df = clean_columns_and_values(df_combined)
    df = process_grupos_column(df)
    df = enrich_parlamentar_and_date(df)
    df = add_analysis_column_and_export_txt(df, txt_filename=output_filename.replace(".xlsx", ".txt"))
    export_for_iramuteq(df, txt_filename=output_filename.replace(".xlsx", "_iramuteq.txt"))

    db = df.copy()
    db.to_excel(output_filename, index=False)
    print(f"‚úÖ Banco de dados limpo salvo como: {output_filename}")
    return db